<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta
http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Mozilla/4.5 [en]
(Win98; I) [Netscape]">
</head>
<body
text="#000000" bgcolor="#FFFFFF" link="#0000EE" vlink="#551A8B" alink="#FF0000">

<h2>

<br>
Research is seeing what everyone else has seen, but thinking what no one
else has thought <br>

<br>

----- Feynman <br>

<br>

Fortune favors the prepared mind <br>

<br>

----- Pasteur

<br><br>

Energy will do anything that can be done in the world.

<br>
----- Johann Wolfgang von Goethe

<br><br>

Newton was a man who wrote a book that neither he nor anybody else could
understand

<br>

----- Cambridge student

<br>

* So since Newton's time, the idea of Quantum Theory has been
developed;  and it could be the reason that some physics books are not
easy to follow.

<br>

-----  the host


<br><br>

If I have ever made any valuable discoveries, it has been owing more to
patient attention, then to any other talent.


-----  Sir Isaac Newton

<br><br>

The essence of knowledge is, having it, to apply it

<br>

----- Confucius

<br>
<br>

Statistical Perspective

<br><br>

In this life nothing is certain but death and taxes

<br>

----- Benjamin Franklin

<br><br>

I look upon quantum mechanics with admiration and suspicion

<br>

------ Albert Einstein

<br><br>

Experiments are the only means of knowledge at our disposal. The rest is poetry, imagination.

------ Planck

<br>
 Q:  When is the time for our imagination to unfold ?

 A: When the mathematical or physical experiment is done.

<br>
--- From a professional mathematician like me.


<br><br>

*** a fundamental idea about entropy

<br><br>

 If there is no uncertainty, then the entropy is zero and we do not have
to make a measurement, because we know what the result will be. No
uncertainty, no information. No pain, no gain.

<br>

Information is associated with uncertainty and entropy. Before we observe
an oscillator, its displacement, momentum, frequency,phase, and energy are
completely uncertain. ......   When entropy is low, a small amount of
information removes a relatively large uncertainty. When entropy is high,
a large amount of information is required.

--- But all of this is statistical, and a.e. we look we see systems with
low entropy, far from thermodyamic equilibrium

<br>
<br>
<br>
<br>
<br>
Bohr:

One must always do what one really cannot

<br>
<br>
<br>
<br>
<br>
David Hilbert(as quoted by Jean Dieudonn\'{e}):

<br> We must know and we shall know

<br>
<br>
in Great Currents of Mathematical Thought, Vol.1
<br>
(Dover Publications, New York, 1971)

<br>

a translation of Les Grandes Courants de la Pens\'{e}e
Math\'{e}matique 
<br>

(Librairie Scientifique et Technique, Paris, 1962)
 </h2>

<ul>

<br>
<br>
<li>
AMS Publications &nbsp; <a href="http://www.ams.org/bookstore/">AMS
Publications</a>
(<a href="math9.html">AMS</a>), Dec.,2000</li>

<li>
AMS Math. Review &nbsp; <a
href="http://www.ams.org/cgi-bin/bookstore/bookpromo/mrsect/">AMS
</a>
(<a href="math9.html">Reviewer discounts</a>), 2000</li>


<li>
Zentralblatt &nbsp; <a
href="http://www.emis.de/ZMATH">Zentralblatt MATH 
</a>
(<a href="math9.html">Zentralblatt MATH </a>), 2001</li>

<li>
Amazon books &nbsp;<a
href="http://www.amazon.com/"> Math. Sci. books</a></li>

</ul>

</body>
</html>

